{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "germanroadsigndet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6BsrYBkvck_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpHM-BOVP-Vy"
      },
      "source": [
        "!cp /content/drive/MyDrive/projects/train_data_aug.tar.gz ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4rBqM7ILPJP"
      },
      "source": [
        "!tar -xzf train_data_aug.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "3ARSJiSKJpj4"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "train_size = 0\n",
        "for dirname, _, filenames in os.walk('/content/work/GTSRB/Final_Training/Images/'):\n",
        "    train_size += len(filenames)\n",
        "\n",
        "print(train_size)\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUwHFKIGMA-9"
      },
      "source": [
        "!pip3 install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lAYAqozSJpkC"
      },
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFRGVelxVeyl"
      },
      "source": [
        "def get_gaussian_filter(kernel_shape):\n",
        "        x = np.zeros(kernel_shape, dtype='float64')\n",
        " \t\t\n",
        "\n",
        "        def gauss(x, y, sigma=2.0):\n",
        "            Z = 2 * np.pi * sigma ** 2\n",
        "            return  1. / Z * np.exp(-(x ** 2 + y ** 2) / (2. * sigma ** 2))\n",
        " \n",
        "        mid = np.floor(kernel_shape[-1] / 2.)\n",
        "        for kernel_idx in range(0, kernel_shape[1]):\n",
        "            for i in range(0, kernel_shape[2]):\n",
        "                for j in range(0, kernel_shape[3]):\n",
        "                    x[0, kernel_idx, i, j] = gauss(i - mid, j - mid)\n",
        " \n",
        "        return x / np.sum(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuizSEaoVkEu"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ref:  https://stackoverflow.com/questions/27948324/implementing-lecun-local-contrast-normalization-with-theano\n",
        "#\n",
        "#       https://github.com/dibyadas/Visualize-Normalizations/blob/master/LocalContrastNorm.ipynb --> not differentiable and\n",
        "#                                efficient ig but provided a way to convert Theano code from above to torch\n",
        "\n",
        "\n",
        "\n",
        "class LCN(nn.Module):\n",
        "  def __init__(self, channels, radius=9):\n",
        "    super(LCN, self).__init__()\n",
        "    self.ch = channels\n",
        "    self.radius = radius\n",
        "    self.filter = nn.Parameter(torch.Tensor(get_gaussian_filter((1, channels, radius, radius))).to(device), requires_grad=False)\n",
        "\n",
        "  def forward(self, image):\n",
        "    radius = self.radius\n",
        "    gaussian_filter = self.filter\n",
        "\n",
        "    filtered_out = F.conv2d(image, gaussian_filter ,padding=radius-1)\n",
        "    mid = int(np.floor(gaussian_filter.shape[2] / 2.))\n",
        "\n",
        "    ### Subtractive Normalization\n",
        "    centered_image = image - filtered_out[:,:,mid:-mid,mid:-mid]\n",
        "\n",
        "    ## Variance Calc\n",
        "    sum_sqr_image = F.conv2d(centered_image.pow(2),gaussian_filter,padding=radius-1)\n",
        "    s_deviation = sum_sqr_image[:,:,mid:-mid,mid:-mid].sqrt()\n",
        "    per_img_mean = s_deviation.mean(axis=[2, 3], keepdim=True)\n",
        "    \n",
        "    p_i_m = torch.unsqueeze(per_img_mean, 2)\n",
        "    p_i_m_ = torch.unsqueeze(p_i_m, 3)\n",
        "\n",
        "    ## Divisive Normalization\n",
        "    divisor = torch.maximum(per_img_mean,s_deviation)\n",
        "    divisor_ = torch.maximum(divisor, torch.tensor(1e-4))\n",
        "    new_image = centered_image / divisor_\n",
        "\n",
        "    return new_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Z46yoGSJpkE"
      },
      "source": [
        "ROOT = '/content/work/GTSRB/Final_Training/Images/'\n",
        "\n",
        "TRANSFORMS = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.341, 0.312, 0.321), (0.275, 0.264, 0.270)),\n",
        "    transforms.Resize((48, 48))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tox4v8CsJpkK"
      },
      "source": [
        "dataset = ImageFolder(root=ROOT, transform=TRANSFORMS)\n",
        "\n",
        "train_data, val_data = random_split(dataset, [320000, 32881])\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=256, num_workers=4)\n",
        "val_loader = DataLoader(val_data, batch_size=256, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "saC_bLEAJpkL"
      },
      "source": [
        "val_data[4][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDn030JiVGE5"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch, filter_size):\n",
        "    super(ConvBlock, self).__init__()\n",
        "\n",
        "    self.lcn_radius = 9\n",
        "\n",
        "    self.block = nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, filter_size, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        LCN(out_ch)\n",
        "    )\n",
        "    # TODO: after maxpool there should be a Local Contrast Response layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFTwpxqoYVpY"
      },
      "source": [
        "class STNBlock(nn.Module):\n",
        "  def __init__(self, in_ch, md_ch, out_ch, last_conv_out_dim, fc_neurons):\n",
        "    super(STNBlock, self).__init__()\n",
        "\n",
        "    self.localization = nn.Sequential(\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(in_ch, md_ch, 5, padding=(2, 2)),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(md_ch, out_ch, 5, padding=(2, 2)),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "\n",
        "    self.fc_loc = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(out_ch * last_conv_out_dim * last_conv_out_dim, fc_neurons),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc_neurons, 2*3)\n",
        "    )\n",
        "\n",
        "    self.fc_loc[3].weight.data.zero_()\n",
        "    self.fc_loc[3].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
        "\n",
        "  def forward(self, x):\n",
        "    xs = self.localization(x)\n",
        "    theta = self.fc_loc(xs)\n",
        "\n",
        "    theta = theta.view(-1, 2, 3)\n",
        "\n",
        "    grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
        "\n",
        "    x = F.grid_sample(x, grid, align_corners=False)\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "molmgB2bJpkN"
      },
      "source": [
        "class Net(pl.LightningModule):\n",
        "    def __init__(self, nb_neurons_fc=400, num_classes=43):\n",
        "        super(Net, self).__init__()\n",
        "        self.t_loss = nn.CrossEntropyLoss()\n",
        "        self.v_loss = nn.CrossEntropyLoss()\n",
        " \n",
        "        self.lcn_preproc = LCN(3)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            STNBlock(3, 250, 250, 6, 250),\n",
        "            ConvBlock(3, 200, 7),\n",
        "            STNBlock(200, 150, 200, 2, 300),\n",
        "            ConvBlock(200, 250, 4),\n",
        "            STNBlock(250, 150, 200, 1, 300),\n",
        "            ConvBlock(250, 350, 4)\n",
        "        )\n",
        " \n",
        "        self.fc_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(350*6*6, nb_neurons_fc),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(nb_neurons_fc, num_classes)\n",
        "        )\n",
        " \n",
        "        #torch.nn.utils.clip_grad_norm_(self.parameters(), 300)\n",
        "        self.epochs = 3\n",
        "        self.best_acc = 98.634\n",
        " \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.lcn_preproc(x)\n",
        "        return self.fc_head(self.net(x))\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        opt = torch.optim.SGD(self.parameters(), lr=1e-2)\n",
        "        return opt\n",
        "    \n",
        "    def training_step(self, batch, idx):\n",
        "        x, y = batch\n",
        "        pred = self(x)\n",
        "        loss = self.t_loss(pred, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validate(self):\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      self.cuda()\n",
        "      print('validating...')\n",
        "      with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "          images, labels = data\n",
        "        \n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          outputs = self(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      acc = 100 * correct / total\n",
        "      print('Accuracy of the network on the test images: {}'.format(acc))\n",
        "      self.epochs += 1\n",
        "  \n",
        "      if acc > self.best_acc:\n",
        "        torch.save(self.state_dict(), 'model_aligncornersF_e{}_a{}'.format(self.epochs, acc))\n",
        "        self.best_acc = acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JrWLAs6bJpkN"
      },
      "source": [
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3q1ewyXvJGT"
      },
      "source": [
        "!cp /content/drive/MyDrive/projects/techmeet_gtsrb/models/model_aligncornersF_dataAug_lcnModule_eunk_a9925.pt  /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFeCYehErKo9"
      },
      "source": [
        "model.load_state_dict(torch.load('model_aligncornersF_dataAug_lcnModule_eunk_a9925.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZekFyCCdRkJE"
      },
      "source": [
        "trainer = pl.Trainer(gpus=1, max_epochs=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ioEYl7zzJpkO"
      },
      "source": [
        "trainer.fit(model, train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjmgN7ubxIXA"
      },
      "source": [
        "model.validate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM5777dEQDjJ"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_aligncornersF_dataAug_lcnModule_eunk_a9925.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lz9PGxRIkn"
      },
      "source": [
        "!cp /content/model_aligncornersF_dataAug_lcnModule_eunk_a9925.pt /content/drive/MyDrive/projects/techmeet_gtsrb/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mBU9VUAgJpkP"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Rrh11K-SJpkQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}